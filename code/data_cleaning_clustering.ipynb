{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the WDI data\n",
    "data=pd.read_csv(\"/Users/leoss/Downloads/P_Data_Extract_From_WDI_Database_Archives-1/wdi_data_capstone_2_11.csv\")\n",
    "data.drop(columns=['Series Code', 'Version Name', 'Version Code'], inplace=True)\n",
    "\n",
    "#Standardise them into long format\n",
    "id_cols = [\n",
    "    'Country Name', 'Country Code', 'Series Name'\n",
    "]\n",
    "Values=[f\"{i} \"+f\"[YR{i}]\" for i in range(1991,2025)]\n",
    "data_long = data.melt(\n",
    "    id_vars=id_cols, \n",
    "    value_vars=Values,\n",
    "    var_name='Year',  \n",
    "    value_name='Value'    \n",
    ")\n",
    "\n",
    "#Coerce all non numerics into Missing data \n",
    "data_long['Value'] = pd.to_numeric(data_long['Value'], errors='coerce')\n",
    "data_long['Year'] = data_long['Year'].str.extract(r'(\\d{4})').astype(int)\n",
    "final_cols = id_cols + ['Year', 'Value']\n",
    "df_long = data_long[final_cols]\n",
    "#print(data_long)\n",
    "\n",
    "# If you are interested in dropping some variables, input them here\n",
    "series_to_drop = ['Tax revenue (% of GDP)', 'Central government debt, total (% of GDP)']\n",
    "df_cleaned = df_long[~df_long['Series Name'].isin(series_to_drop)]\n",
    "#df_cleaned[\"Country Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Trade data on complexity\n",
    "trade=pd.read_csv(\"/Users/leoss/Downloads/growth_proj_eci_rankings.csv\")\n",
    "columns1 = [\"country_id\",'growth_proj', 'in_rankings', 'eci_sitc', 'eci_rank_sitc','eci_rank_hs92', 'eci_hs12', 'eci_rank_hs12']\n",
    "trade.drop(columns1, inplace=True, axis=1) \n",
    "\n",
    "#Standardise names and order\n",
    "trade[\"Series Name\"]=\"Economic Complexity\"\n",
    "trade = trade.rename(columns={\n",
    "    \"country_iso3_code\": \"Country Code\",\n",
    "    \"Country\":\"Country Name\",\n",
    "    \"year\": \"Year\",\n",
    "    \"eci_hs92\": \"Value\"\n",
    "})\n",
    "new_order = ['Country Code','Series Name', 'Year', 'Value' ]\n",
    "trade = trade[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import imf dataset\n",
    "ins = [\"COUNTRY.ID\", \"COUNTRY\", \"INDICATOR\", \"TIME_PERIOD\", \n",
    "       \"OBS_VALUE\", \"SCALE.ID\", \"PRIMARY_DOMESTIC_CURRENCY\"]\n",
    "imf = pd.read_csv(\n",
    "    \"/Users/leoss/Downloads/WorldEconomicOutlook-1.csv\", \n",
    "    usecols=ins\n",
    ")\n",
    "#Only include relevant variables\n",
    "imf = imf[ins]\n",
    "\n",
    "#Dropping all observations without an associated time period and rename \n",
    "imf[\"TIME_PERIOD\"].dropna(inplace=True)\n",
    "imf = imf.rename(columns={\n",
    "    \"COUNTRY.ID\": \"Country Code\",\n",
    "    \"COUNTRY\":\"Country Name\",\n",
    "    \"TIME_PERIOD\": \"Year\",\n",
    "    \"INDICATOR\":\"Series Name\",\n",
    "    \"OBS_VALUE\": \"Value\"\n",
    "})\n",
    "\n",
    "#Extract value scaled\n",
    "imf[\"Value\"]=imf[\"Value\"]*10**(imf[\"SCALE.ID\"])\n",
    "\n",
    "#Drop those as not needed anymore\n",
    "imf.drop(columns=[\"SCALE.ID\",\"PRIMARY_DOMESTIC_CURRENCY\"], inplace=True)\n",
    "\n",
    "#Choose variables of interest\n",
    "raw_list = [\n",
    "    \"Gross domestic product (GDP), Per capita, purchasing power parity (PPP) international dollar, ICP benchmarks 2017-2021\",\n",
    "    \"Current account balance (credit less debit), US dollar\",\n",
    "    \"Revenue, General government, Percent of GDP\"\n",
    "]\n",
    "variables_to_keep = [s.strip() for s in raw_list]\n",
    "imf = imf[imf['Series Name'].isin(variables_to_keep)].query(\"Year>1990 & Year<2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique country codes from each database\n",
    "codes_cleaned = set(df_cleaned['Country Code'].unique())\n",
    "codes_trade = set(trade['Country Code'].unique())\n",
    "codes_imf = set(imf['Country Code'].unique())\n",
    "common_codes = codes_cleaned.intersection(codes_trade, codes_imf)\n",
    "print(f\"Found {len(common_codes)} countries common to all datasets.\")\n",
    "\n",
    "#Filter the original dataframes to keep only the common codes\n",
    "df_cleaned_filtered = df_cleaned[df_cleaned['Country Code'].isin(common_codes)].copy()\n",
    "trade_filtered = trade[trade['Country Code'].isin(common_codes)].copy()\n",
    "imf_filtered = imf[imf['Country Code'].isin(common_codes)].copy()\n",
    "\n",
    "#Final merge\n",
    "final_dataset = pd.concat([df_cleaned_filtered, trade_filtered, imf_filtered], ignore_index=True)\n",
    "final_dataset.sort_values(by=['Country Code', 'Year'], inplace=True)\n",
    "final_dataset.dropna(subset=['Country Code'], inplace=True)\n",
    "#final_dataset[\"Series Name\"].value_counts()\n",
    "\n",
    "##The final dataset will struggle with Name-Code matchings\n",
    "\"\"\"\n",
    "country_name_map = final_dataset.groupby('Country Code')['Country Name'].unique().reset_index()\n",
    "def clean_name_list(name_list):\n",
    "    clean_list = []\n",
    "    for name in name_list:\n",
    "        if pd.notna(name):\n",
    "            clean_list.append(str(name))\n",
    "    return clean_list\n",
    "\n",
    "country_name_map['Cleaned_Names'] = country_name_map['Country Name'].apply(clean_name_list)\n",
    "country_name_map['Valid_Name_Count'] = country_name_map['Cleaned_Names'].apply(len)\n",
    "\n",
    "# Check for duplicate names for the same Country Code\n",
    "conflicts_found = False\n",
    "no_name_count = 0\n",
    "single_name_count = 0\n",
    "\n",
    "for index, row in country_name_map.iterrows():\n",
    "    code = row['Country Code']\n",
    "    names = row['Cleaned_Names']\n",
    "    count = row['Valid_Name_Count']\n",
    "    if count > 1:\n",
    "        print(f\"Code:'{code}' maps to multiple names: {names}\")\n",
    "        conflicts_found = True\n",
    "    elif count == 0:\n",
    "        print(f\"Code': {code}' only has missing (NaN) Country Names associated with it.\")\n",
    "        no_name_count += 1\n",
    "    else:\n",
    "        single_name_count += 1\n",
    "\n",
    "print(f\"\\nTotal codes with one unique name: {single_name_count}\")\n",
    "print(f\"Total codes with no valid name: {no_name_count}\")\n",
    "print(f\"Total unique codes checked: {len(country_name_map)}\")\n",
    "\"\"\"\n",
    "#Manually fixing the names:\n",
    "mapping={\"AFG\":'Afghanistan',\n",
    "         'ARM':'Armenia',\n",
    "         'AZE':'Azerbaijan',\n",
    "         'BHR':'Bahrain',\n",
    "         'BLR':'Belarus',\n",
    "         'CHN':'China',\n",
    "         'CIV':\"Cote d'Ivoire\",\n",
    "         'COD':'Congo Dem. Rep.',\n",
    "         'COG':'Congo',\n",
    "         'EGY':\"Egypt\",\n",
    "         'EST':'Estonia',\n",
    "         'ETH':'Ethiopia',\n",
    "         'GNQ':'Equatorial Guinea',\n",
    "         'HKG':'Hong Kong',\n",
    "         'HRV':'Croatia',\n",
    "         'IRN':'Iran',\n",
    "         'KAZ':'Kazakhstan',\n",
    "         'LAO':'Laos',\n",
    "         \"LTU\":'Lithuania',\n",
    "         'LVA':'Latvia',\n",
    "         'MDA':'Moldova',\n",
    "         'KOR':'South Korea',\n",
    "         'KAZ':'Kazakhstan',\n",
    "         'MDG':'Madagascar',\n",
    "         'MKD':'North Macedonia',\n",
    "         'MOZ':'Mozambique',\n",
    "         'MRT':'Mauritania',\n",
    "         'NLD':'Netherlands',\n",
    "         'POL':'Poland',\n",
    "         'RUS':'Russia',\n",
    "         'SRB':'Serbia',\n",
    "         'SVN':'Slovenia',\n",
    "         'SWZ':'Eswatini',\n",
    "         'TJK':'Tajikistan',\n",
    "         'TUR':'Turkey',\n",
    "         'TWN':'Taiwan',\n",
    "         'UZB':'Uzbekistan',\n",
    "         'VEN':'Venezuela',\n",
    "         'YEM':'Yemen'\n",
    "         }\n",
    "# Create a Series of new names from the map\n",
    "new_names = final_dataset['Country Code'].map(mapping)\n",
    "final_dataset['Country Name'] = new_names.fillna(final_dataset['Country Name'])\n",
    "\n",
    "#Now generate code-name pairing, to fill missing country-names\n",
    "valid_names = final_dataset.dropna(subset=['Country Name'])\n",
    "code_to_name_map_df = valid_names.drop_duplicates(subset=['Country Code'])\n",
    "clean_map_dict = pd.Series(\n",
    "    code_to_name_map_df['Country Name'].values, \n",
    "    index=code_to_name_map_df['Country Code']\n",
    ").to_dict()\n",
    "filled_names = final_dataset['Country Code'].map(clean_map_dict)\n",
    "final_dataset['Country Name'] = final_dataset['Country Name'].fillna(filled_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
